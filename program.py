import streamlit as st
import pandas as pd
import numpy as np
import torch
import google.generativeai as genai
import json
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import io
import os


# --- [1. í™˜ê²½ ì„¤ì • ë° API ì—°ê²°] ---
st.set_page_config(page_title="Data Preprocessing Agent", layout="wide")

GEMINI_API_KEY = None

# .streamlit/secrets.toml íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸ (ì—ëŸ¬ ë°•ìŠ¤ ë°©ì§€)
secrets_exist = False
try:
    if os.path.exists(".streamlit/secrets.toml"):
        secrets_exist = True
    elif os.path.exists(os.path.join(os.path.expanduser("~"), ".streamlit", "secrets.toml")):
        secrets_exist = True
except:
    pass

if secrets_exist:
    try:
        if "GEMINI_API_KEY" in st.secrets:
            GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    except:
        pass

if not GEMINI_API_KEY:
    # secretsê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ë°›ê±°ë‚˜ ì—ëŸ¬ë¥¼ ë„ì›ë‹ˆë‹¤ (ë³´ì•ˆìƒ ì•ˆì „)
    GEMINI_API_KEY = st.text_input("Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    if not GEMINI_API_KEY:
        st.warning("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ ì‹¤í–‰ ì‹œ .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

genai.configure(api_key=GEMINI_API_KEY)
# model = genai.GenerativeModel('gemini-pro') 
model = genai.GenerativeModel('gemini-2.5-flash') # Or gemini-1.5-pro-latest


# Toss ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ CSS (ë‹¨ê³„ë³„ ì§„í–‰ ë°” ë“± ì¶”ê°€)
st.markdown("""
    <style>
    .main { background-color: #F9FAFB; }
    .stButton>button { width: 100%; border-radius: 12px; height: 3em; background-color: #0047FF; color: white; font-weight: bold; border: none; }
    .stProgress > div > div > div > div { background-color: #0047FF; }
    div[data-testid="stExpander"] { background-color: white; border-radius: 10px; border: 1px solid #E5E7EB; }
    </style>
""", unsafe_allow_html=True)

# --- [2. ë„êµ¬ í•¨ìˆ˜ë“¤] ---
def get_agent_plan(df, goal, target_col):
    """Geminiê°€ ì „ì²´ ì „ì²˜ë¦¬ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤."""
    sample_data = df.head(5).to_csv(index=False)
    null_info = df.isnull().mean().to_dict()
    column_types = df.dtypes.astype(str).to_dict()
    unique_counts = df.nunique().to_dict()
    
    prompt = f"""
    ë‹¹ì‹ ì€ ë°ì´í„° ì „ì²˜ë¦¬ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ëª©í‘œ: {goal}
    íƒ€ê²Ÿ ì»¬ëŸ¼(ì˜ˆì¸¡ ë³€ìˆ˜): {target_col} (ì´ ì»¬ëŸ¼ì€ ì‚­ì œí•˜ì§€ ë§ê³ , ì ì ˆí•œ ì¸ì½”ë”©ì´ë‚˜ ì²˜ë¦¬ë¥¼ ì œì•ˆí•˜ì„¸ìš”.)
    ë°ì´í„° ìƒ˜í”Œ: {sample_data}
    ê²°ì¸¡ë¥ : {null_info}
    íƒ€ì…: {column_types}
    Unique ê°’ ê°œìˆ˜: {unique_counts}
    
    ê° ì»¬ëŸ¼ë³„ë¡œ [Drop, Fill_Median, Fill_Mode, Fill_Zero, Normalize, Encode_OneHot, Encode_Label, Pass] ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ ë‹¨ê³„ë³„ ê³„íšì„ ì„¸ìš°ì„¸ìš”.
    
    ê·œì¹™:
    1. ë²”ì£¼í˜• ë°ì´í„°(object)ëŠ” ë°˜ë“œì‹œ Encode_OneHot(ì¹´í…Œê³ ë¦¬ ìˆ˜ ì ì„ ë•Œ) ë˜ëŠ” Encode_Label(ë§ì„ ë•Œ)ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
    2. íƒ€ê²Ÿ ì»¬ëŸ¼ì¸ '{target_col}'ì€ ì ˆëŒ€ Dropí•˜ì§€ ë§ˆì„¸ìš”. ë²”ì£¼í˜•ì´ë©´ Encode_Label, ìˆ˜ì¹˜í˜•ì´ë©´ Passë‚˜ Normalizeë¥¼ ì¶”ì²œí•˜ì„¸ìš”.
    3. JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    
    [
        {{"col": "ì»¬ëŸ¼ëª…", "action": "ì„ íƒí•œ ì•¡ì…˜", "reason": "ì´ìœ (í•œê¸€)"}}
    ]
    """
    try:
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except Exception as e:
        print(f"Error calling Gemini: {e}") 
        return [{"col": c, "action": "Pass", "reason": f"API ì˜¤ë¥˜ë¡œ ê¸°ë³¸ Pass ì²˜ë¦¬ ({str(e)})"} for c in df.columns]

def apply_step(df, col, action):
    """ë‹¨ì¼ ìŠ¤í…(ì»¬ëŸ¼ ì•¡ì…˜)ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    new_df = df.copy()
    
    if col not in new_df.columns:
        return new_df

    try:
        if action == "Drop":
            new_df = new_df.drop(columns=[col])
        elif action == "Fill_Median":
            if pd.api.types.is_numeric_dtype(new_df[col]):
                val = new_df[col].median()
                new_df[col] = new_df[col].fillna(val)
        elif action == "Fill_Mode":
            val = new_df[col].mode()[0]
            new_df[col] = new_df[col].fillna(val)
        elif action == "Fill_Zero":
            new_df[col] = new_df[col].fillna(0)
        elif action == "Normalize":
            if pd.api.types.is_numeric_dtype(new_df[col]):
                scaler = StandardScaler()
                data = new_df[[col]].values
                new_df[col] = scaler.fit_transform(data).flatten()
        elif action == "Encode_Label":
            le = LabelEncoder()
            # ê²°ì¸¡ì¹˜ëŠ” ì„ì‹œ ì²˜ë¦¬ í›„ ì¸ì½”ë”©
            new_df[col] = new_df[col].fillna("Unknown").astype(str)
            new_df[col] = le.fit_transform(new_df[col])
        elif action == "Encode_OneHot":
            # One-Hotì€ ì»¬ëŸ¼ì´ ëŠ˜ì–´ë‚˜ë¯€ë¡œ ì²˜ë¦¬ê°€ ì¡°ê¸ˆ ë‹¤ë¦…ë‹ˆë‹¤.
            # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” í•´ë‹¹ ì»¬ëŸ¼ì„ ì›í•« ì¸ì½”ë”©í•œ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.
            dummies = pd.get_dummies(new_df[col], prefix=col, drop_first=False)
            new_df = pd.concat([new_df.drop(columns=[col]), dummies], axis=1)
            
    except Exception as e:
        st.error(f"Action '{action}' failed on '{col}': {e}")
            
    return new_df

def plot_comparison(old_df, new_df, col):
    """ë³€ê²½ ì „í›„ ë¶„í¬ ë¹„êµ ì‹œê°í™” (Plotly)"""
    # 1. ì»¬ëŸ¼ì´ ì‚¬ë¼ì§„ ê²½ìš° (Drop, OneHot ë“±)
    if col not in new_df.columns:
        st.info(f"â„¹ï¸ '{col}' ì»¬ëŸ¼ì€ ì²˜ë¦¬ í›„ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ì˜ˆ: One-Hot Encoding)")
        return

    col_c1, col_c2 = st.columns(2)
    
    # 2. ìˆ˜ì¹˜í˜• ë°ì´í„° ì‹œê°í™”
    if pd.api.types.is_numeric_dtype(new_df[col]):
        with col_c1:
            # Histogram
            fig = go.Figure()
            # Original
            fig.add_trace(go.Histogram(x=old_df[col].dropna(), name='Original', opacity=0.5, marker_color='gray'))
            # Transformed
            fig.add_trace(go.Histogram(x=new_df[col], name='Transformed', opacity=0.5, marker_color='blue'))
            fig.update_layout(title_text=f"{col} Distribution (Histogram)", barmode='overlay')
            st.plotly_chart(fig, use_container_width=True)
            
        with col_c2:
            # Box Plot
            fig2 = go.Figure()
            fig2.add_trace(go.Box(y=old_df[col].dropna(), name='Original', marker_color='gray'))
            fig2.add_trace(go.Box(y=new_df[col], name='Transformed', marker_color='blue'))
            fig2.update_layout(title_text=f"{col} Box Plot (Outliers)")
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("#### ğŸ”¢ í†µê³„ ìš”ì•½")
        desc_old = old_df[col].describe()
        desc_new = new_df[col].describe()
        stats_df = pd.DataFrame({'Original': desc_old, 'Transformed': desc_new})
        st.dataframe(stats_df.T, use_container_width=True)

    # 3. ë²”ì£¼í˜• ë°ì´í„° ì‹œê°í™”
    else:
        # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬
        top_n = 10
        old_counts = old_df[col].value_counts().head(top_n)
        new_counts = new_df[col].value_counts().head(top_n)
        
        with col_c1:
            fig = px.bar(x=old_counts.index, y=old_counts.values, title=f"Original Top {top_n}", labels={'x':'Category', 'y':'Count'})
            st.plotly_chart(fig, use_container_width=True)
            
        with col_c2:
            fig2 = px.bar(x=new_counts.index, y=new_counts.values, title=f"Transformed Top {top_n}", labels={'x':'Category', 'y':'Count'})
            st.plotly_chart(fig2, use_container_width=True)

# --- [3. ë©”ì¸ ë¡œì§] ---
if 'step' not in st.session_state:
    st.session_state.step = 'upload'
    st.session_state.current_step_idx = 0
    st.session_state.log = [] 

st.title("ğŸ¤– Advanced AI Data Preprocessing Agent")

# [Step 1] ë°ì´í„° ì—…ë¡œë“œ & ëª©í‘œ & íƒ€ê²Ÿ ì„¤ì •
if st.session_state.step == 'upload':
    st.subheader("1. ë°ì´í„° & ëª©í‘œ ì„¤ì •")
    uploaded_file = st.file_uploader("CSV ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", type="csv")
    user_goal = st.text_input("ë¶„ì„ ëª©í‘œ (ì˜ˆ: íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡)", placeholder="ì´ ë°ì´í„°ë¡œ ë¬´ì—‡ì„ í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?")
    
    if uploaded_file:
        # ì„ì‹œë¡œ ì½ì–´ì„œ ì»¬ëŸ¼ ëª©ë¡ ë³´ì—¬ì£¼ê¸°
        temp_df = pd.read_csv(uploaded_file)
        st.write("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        st.dataframe(temp_df.head(3))
        
        target_col = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ì»¬ëŸ¼(ì˜ˆì¸¡í•  ì •ë‹µ)ì„ ì„ íƒí•˜ì„¸ìš”:", temp_df.columns)
        
        if user_goal and st.button("AIì—ê²Œ ê³„íš ìš”ì²­í•˜ê¸° ğŸš€"):
            st.session_state.original_df = temp_df
            st.session_state.df = st.session_state.original_df.copy()
            st.session_state.goal = user_goal
            st.session_state.target_col = target_col
            st.session_state.history = []
            
            with st.spinner("Geminiê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì „ì²˜ë¦¬ ì „ëµì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤..."):
                plan = get_agent_plan(st.session_state.df, user_goal, target_col)
                st.session_state.plan = plan
                st.session_state.step = 'plan_edit' # ìƒˆë¡œìš´ ë‹¨ê³„
                st.rerun()

# [Step 2] ê³„íš ê²€í†  ë° ìˆ˜ì • (Plan Editor)
elif st.session_state.step == 'plan_edit':
    st.subheader("2. AI ì œì•ˆ ì „ì²˜ë¦¬ ê³„íš ê²€í† ")
    st.info("AIê°€ ì œì•ˆí•œ ê³„íšì…ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ -> DataFrame ë³€í™˜
    plan_df = pd.DataFrame(st.session_state.plan)
    
    # ìˆ˜ì • ê°€ëŠ¥í•œ Data Editor
    edited_plan_df = st.data_editor(
        plan_df,
        column_config={
            "col": st.column_config.TextColumn("ì»¬ëŸ¼ëª…", disabled=True),
            "action": st.column_config.SelectboxColumn(
                "ì•¡ì…˜",
                options=["Pass", "Drop", "Fill_Median", "Fill_Mode", "Fill_Zero", "Normalize", "Encode_Label", "Encode_OneHot"],
                required=True
            ),
            "reason": st.column_config.TextColumn("ì´ìœ  (AI ìƒì„±)", disabled=True)
        },
        use_container_width=True,
        hide_index=True,
        num_rows="fixed"
    )
    
    col1, col2 = st.columns(2)
    if col1.button("ì´ëŒ€ë¡œ ì‹¤í–‰í•˜ê¸° â–¶ï¸", type="primary"):
        # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        st.session_state.plan = edited_plan_df.to_dict('records')
        st.session_state.step = 'execute_loop'
        st.rerun()
        
    if col2.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.session_state.step = 'upload'
        st.rerun()

# [Step 3] ì‹¤í–‰ ë£¨í”„
elif st.session_state.step == 'execute_loop':
    plan = st.session_state.plan
    idx = st.session_state.current_step_idx
    
    if idx < len(plan):
        current_item = plan[idx]
        col = current_item['col']
        action = current_item['action']
        reason = current_item['reason']
        
        # ì´ë¯¸ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì»¬ëŸ¼ì´ ì‚¬ë¼ì¡Œì„ ìˆ˜ë„ ìˆìŒ (ì˜ˆ: ì´ì „ ë‹¨ê³„ì˜ OneHot ë“±)
        # í•˜ì§€ë§Œ ì›ë³¸ ì»¬ëŸ¼ëª… ê¸°ì¤€ ë£¨í”„ì´ë¯€ë¡œ, í˜„ì¬ dfì— colì´ ìˆëŠ”ì§€ ì²´í¬ í•„ìš”
        col_exists = col in st.session_state.df.columns
        
        progress = (idx / len(plan))
        st.progress(progress, text=f"Processing... ({int(progress*100)}%)")
        
        st.subheader(f"Step {idx+1}/{len(plan)}: {col}")
        
        if not col_exists:
            st.warning(f"âš ï¸ ì»¬ëŸ¼ '{col}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ë³€í˜•ë¨)")
            # ìë™ ìŠ¤í‚µ
            if st.button("ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ê¸°"):
                st.session_state.log.append(f"Step {idx+1}: {col} -> Skipped (Not Found)")
                st.session_state.current_step_idx += 1
                st.rerun()
            st.stop()

        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.markdown(f"**{col}** â†’ **`{action}`**")
            st.caption(f"Reason: {reason}")

        # Preview
        preview_df = apply_step(st.session_state.df, col, action)
        
        with st.expander("ğŸ” ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (Interactive Chart)", expanded=True):
            if action != "Drop":
                plot_comparison(st.session_state.df, preview_df, col)
            else:
                st.error(f"ğŸ—‘ï¸ '{col}' ì»¬ëŸ¼ì´ ì œê±°ë©ë‹ˆë‹¤.")

        st.write("---")
        c1, c2, c3 = st.columns(3)
        if c1.button("âœ… ìŠ¹ì¸ (Apply)", type="primary", use_container_width=True):
            st.session_state.history.append(st.session_state.df.copy())
            st.session_state.df = preview_df
            st.session_state.log.append(f"{col}: {action}")
            st.session_state.current_step_idx += 1
            st.rerun()
            
        if c2.button("âŒ ê±´ë„ˆë›°ê¸° (Pass)", use_container_width=True):
            st.session_state.history.append(st.session_state.df.copy())
            # df ë³€ê²½ ì—†ìŒ
            st.session_state.log.append(f"{col}: Pass (User Skipped)")
            st.session_state.current_step_idx += 1
            st.rerun()
            
        if c3.button("â†©ï¸ ì‹¤í–‰ ì·¨ì†Œ (Undo)", use_container_width=True):
            if st.session_state.history:
                st.session_state.df = st.session_state.history.pop()
                if st.session_state.log: st.session_state.log.pop()
                st.session_state.current_step_idx -= 1
                st.rerun()
            else:
                st.warning("ëŒì•„ê°ˆ ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

    else:
        st.session_state.step = 'final'
        st.rerun()

# [Step 4] ì™„ë£Œ ë° ë‹¤ìš´ë¡œë“œ
elif st.session_state.step == 'final':
    st.balloons()
    st.success("ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    final_df = st.session_state.df
    target_col = st.session_state.target_col
    
    st.subheader("ğŸ“Š ìµœì¢… ë°ì´í„° ìš”ì•½")
    st.dataframe(final_df.head())
    st.write(f"Shape: {final_df.shape}")
    
    with st.expander("ï¿½ï¸ ì²˜ë¦¬ ë¡œê·¸"):
        for l in st.session_state.log:
            st.text(l)
            
    # Tensor ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
    if st.button("Generate PyTorch Tensors"):
        # 1. Target ë¶„ë¦¬ attempt
        if target_col in final_df.columns:
            # íƒ€ê²Ÿì´ ë³€í˜•ë˜ì§€ ì•Šì•˜ê±°ë‚˜ LabelEncodingëœ ìƒíƒœ
            y = final_df[target_col]
            X = final_df.drop(columns=[target_col])
        else:
            # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ OneHot ë“±ìœ¼ë¡œ ì´ë¦„ì´ ë°”ë€Œì—ˆê±°ë‚˜ ì‚¬ë¼ì¡Œì„ ìˆ˜ ìˆìŒ
            # ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ë§Œì•½ íƒ€ê²Ÿì´ ì—†ìœ¼ë©´ ê°€ì¥ ë§ˆì§€ë§‰ ì»¬ëŸ¼ì„ íƒ€ê²Ÿìœ¼ë¡œ ê°€ì •í•˜ê±°ë‚˜,
            # OneHotëœ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì„œ yë¡œ ë¬¶ì–´ì¤˜ì•¼ í•¨.
            # ì§€ê¸ˆì€ ê°„ë‹¨íˆ ê²½ê³  í›„ ì „ì²´ë¥¼ Xë¡œ.
            st.warning(f"íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_col}'ì´(ê°€) ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. One-Hot Encoding ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì´ë¦„ì— target_colì´ í¬í•¨ëœ ì»¬ëŸ¼ë“¤ì„ yë¡œ ê°„ì£¼ (ê°„ì´ ë¡œì§)
            target_cols = [c for c in final_df.columns if str(c).startswith(f"{target_col}_")]
            if target_cols:
                y = final_df[target_cols]
                X = final_df.drop(columns=target_cols)
                st.info(f"íƒ€ê²Ÿìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì»¬ëŸ¼ë“¤: {target_cols}")
            else:
                st.error("íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ë¥¼ Xë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                X = final_df
                y = pd.Series(np.zeros(len(X))) # Dummy y

        # 2. ëª¨ë‘ ìˆ«ìì¸ì§€ í™•ì¸
        try:
            # í…ì„œ ë³€í™˜ì„ ìœ„í•´ object íƒ€ì… ë“±ì´ ë‚¨ì•„ìˆìœ¼ë©´ ê°•ì œ ë³€í™˜ ì‹œë„ or ì—ëŸ¬
            # ì—¬ê¸°ì„œ numeric_only=Trueë¥¼ í•˜ë©´ ë°ì´í„° ìœ ì‹¤ë¨. 
            # ì•ë‹¨ê³„ì—ì„œ Encodingì„ ê°•ì œí–ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„  coerceë¡œ ë³€í™˜ ì‹œë„
            X = X.apply(pd.to_numeric, errors='coerce').fillna(0)
            
            # y ì²˜ë¦¬
            if isinstance(y, pd.DataFrame): # OneHotëœ target
                 y = y.apply(pd.to_numeric, errors='coerce').fillna(0).values
            else:
                 y = pd.to_numeric(y, errors='coerce').fillna(0).values

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            X_train_t = torch.tensor(X_train.values, dtype=torch.float32).to(device)
            X_test_t = torch.tensor(X_test.values, dtype=torch.float32).to(device)
            y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
            y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)
            
            st.write(f"X_train: {X_train_t.shape}, y_train: {y_train_t.shape}")
            
            # Save
            buffer = io.BytesIO()
            torch.save({
                'X_train': X_train_t, 'X_test': X_test_t,
                'y_train': y_train_t, 'y_test': y_test_t,
                'feature_names': list(X.columns)
            }, buffer)
            
            st.download_button("ğŸ’¾ Download .pt file", buffer.getvalue(), "data.pt")
            
        except Exception as e:
            st.error(f"í…ì„œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.caption("ëª¨ë“  ì»¬ëŸ¼ì´ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    if st.button("Restart"):
        st.session_state.clear()
        st.rerun()