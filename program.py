import streamlit as st
import pandas as pd
import numpy as np
import torch
import google.generativeai as genai
import json
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import io
import os


def generate_html_report(df_info, goal, target, plan, logs, metrics):
    """Generates a simple HTML report summary."""
    html = f"""
    <html>
    <head>
        <title>Data Preprocessing Report</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }}
            h1 {{ color: #2c3e50; }}
            h2 {{ color: #34495e; margin-top: 30px; }}
            .card {{ background: #f8f9fa; border-left: 5px solid #3498db; padding: 15px; margin-bottom: 20px; }}
            table {{ border-collapse: collapse; width: 100%; margin-top: 10px; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“Š AI Data Preprocessing Report</h1>
        <p>Generated by Tensorifier Agent</p>
        
        <div class="card">
            <h2>1. Project Overview</h2>
            <ul>
                <li><strong>Goal:</strong> {goal}</li>
                <li><strong>Target Variable:</strong> {target}</li>
                <li><strong>Final Data Shape:</strong> {df_info}</li>
            </ul>
        </div>

        <div class="card">
            <h2>2. Execution Metrics</h2>
            <p>{metrics}</p>
        </div>

        <h2>3. Applied Preprocessing Steps</h2>
        <table>
            <tr><th>Column</th><th>Action</th><th>Reason</th></tr>
    """
    for item in plan:
        html += f"<tr><td>{item['col']}</td><td>{item['action']}</td><td>{item.get('reason', '-')}</td></tr>"
    
    html += """
        </table>

        <h2>4. Execution Log</h2>
        <ul>
    """
    for log in logs:
        html += f"<li>{log}</li>"
    
    html += """
        </ul>
    </body>
    </html>
    """
    return html

def generate_python_code(plan, target_col):
    """ì „ì²˜ë¦¬ ê³¼ì •ì„ íŒŒì´ì¬ ì½”ë“œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    code = f"""import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import torch

# 1. Load Data
# df = pd.read_csv('your_data_file.csv') # Replace with your file path

# 2. Preprocessing Steps
"""
    for item in plan:
        col = item['col']
        action = item['action']
        if action == "Pass": continue
        
        code += f"\n# [{col}] - {action}\n"
        code += f"if '{col}' in df.columns:\n"
        
        if action == "Drop":
            code += f"    df = df.drop(columns=['{col}'])\n"
        elif action == "Fill_Median":
            code += f"    if pd.api.types.is_numeric_dtype(df['{col}']):\n"
            code += f"        val = df['{col}'].median()\n"
            code += f"        df['{col}'] = df['{col}'].fillna(val)\n"
        elif action == "Fill_Mode":
            code += f"    val = df['{col}'].mode()[0]\n"
            code += f"    df['{col}'] = df['{col}'].fillna(val)\n"
        elif action == "Fill_Zero":
            code += f"    df['{col}'] = df['{col}'].fillna(0)\n"
        elif action == "Normalize":
            code += f"    scaler = StandardScaler()\n"
            code += f"    df['{col}'] = scaler.fit_transform(df[['{col}']].values).flatten()\n"
        elif action == "Encode_Label":
            code += f"    le = LabelEncoder()\n"
            code += f"    df['{col}'] = df['{col}'].fillna('Unknown').astype(str)\n"
            code += f"    df['{col}'] = le.fit_transform(df['{col}'])\n"
        elif action == "Encode_OneHot":
            code += f"    dummies = pd.get_dummies(df['{col}'], prefix='{col}', drop_first=False)\n"
            code += f"    df = pd.concat([df.drop(columns=['{col}']), dummies], axis=1)\n"

    code += f"""
# 3. Target Separation & Tensor Creation
target_col = '{target_col}'
if target_col in df.columns:
    y = df[target_col].values
    X = df.drop(columns=[target_col])
else:
    # Handle One-Hot case
    target_cols = [c for c in df.columns if str(c).startswith(f"{{target_col}}_")]
    if target_cols:
        y = df[target_cols].values
        X = df.drop(columns=target_cols)
    else:
        print("Target column not found. Using all columns as X.")
        X = df
        y = np.zeros(len(df))

# Feature Type Cleaning
X = X.apply(pd.to_numeric, errors='coerce').fillna(0)
X_values = X.values.astype(np.float32)

# y handling
try:
    y = pd.to_numeric(y, errors='coerce')
    y = np.nan_to_num(y)
except:
    pass
y_values = np.array(y).astype(np.float32)

# Split
X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size=0.2, random_state=42)

# Convert to PyTorch Tensors
device = "cuda" if torch.cuda.is_available() else "cpu"
X_train_t = torch.tensor(X_train).to(device)
y_train_t = torch.tensor(y_train).to(device)

print(f"Propocessing Complete. X_train shape: {{X_train_t.shape}}")
"""
def generate_dask_code(plan, target_col):
    """Generates Dask code for Big Data processing (Lazy Evaluation)."""
    code = f"""import dask.dataframe as dd
import dask.array as da
import numpy as np

# 1. Load Data (Lazy Loading for Big Data > 100GB)
# ddf = dd.read_csv('your_big_data_*.csv') 
# client = Client() # Connect to cluster if needed

# 2. Preprocessing Steps
"""
    for item in plan:
        col = item['col']
        action = item['action']
        if action == "Pass": continue
        
        code += f"\n# [{col}] - {action}\n"
        # Dask uses lazy columns presence check usually, but for script generation we assume schema allows it.
        # We wrap in check logic if needed, but schema is usually fixed.
        code += f"# Action: {action}\n"
        
        if action == "Drop":
            code += f"if '{col}' in ddf.columns: ddf = ddf.drop(columns=['{col}'])\n"
        elif action == "Fill_Median":
            code += f"if '{col}' in ddf.columns:\n"
            code += f"    median_val = ddf['{col}'].median().compute() # Computes immediately\n"
            code += f"    ddf['{col}'] = ddf['{col}'].fillna(median_val)\n"
        elif action == "Fill_Mode":
            code += f"if '{col}' in ddf.columns:\n"
            code += f"    mode_val = ddf['{col}'].mode().compute().iloc[0]\n"
            code += f"    ddf['{col}'] = ddf['{col}'].fillna(mode_val)\n"
        elif action == "Fill_Zero":
             code += f"if '{col}' in ddf.columns: ddf['{col}'] = ddf['{col}'].fillna(0)\n"
        elif action == "Normalize":
            code += f"if '{col}' in ddf.columns:\n"
            code += f"    mean = ddf['{col}'].mean().compute()\n"
            code += f"    std = ddf['{col}'].std().compute()\n"
            code += f"    ddf['{col}'] = (ddf['{col}'] - mean) / std\n"
        elif action == "Encode_Label":
            code += f"if '{col}' in ddf.columns:\n"
            code += f"    ddf['{col}'] = ddf['{col}'].astype('category').cat.as_known().cat.codes\n"
        elif action == "Encode_OneHot":
            code += f"if '{col}' in ddf.columns:\n"
            code += f"    ddf = dd.get_dummies(ddf, columns=['{col}'])\n"

    code += f"""
# 3. Target & Output
target_col = '{target_col}'
# Dask operations are lazy. Trigger computation or save to parquet.
print("Saving processed data to Parquet (Distributed Write)...")
# ddf.to_parquet('processed_output.parquet')
print("Done.")
"""
    return code


# --- [1. í™˜ê²½ ì„¤ì • ë° API ì—°ê²°] ---
# ... (rest of the file)


# --- [1. í™˜ê²½ ì„¤ì • ë° API ì—°ê²°] ---
st.set_page_config(page_title="Data Preprocessing Agent", layout="wide")

GEMINI_API_KEY = None

# .streamlit/secrets.toml íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸ (ì—ëŸ¬ ë°•ìŠ¤ ë°©ì§€)
secrets_exist = False
try:
    if os.path.exists(".streamlit/secrets.toml"):
        secrets_exist = True
    elif os.path.exists(os.path.join(os.path.expanduser("~"), ".streamlit", "secrets.toml")):
        secrets_exist = True
except:
    pass

if secrets_exist:
    try:
        if "GEMINI_API_KEY" in st.secrets:
            GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    except:
        pass

if not GEMINI_API_KEY:
    # secretsê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ì„ ë°›ê±°ë‚˜ ì—ëŸ¬ë¥¼ ë„ì›ë‹ˆë‹¤ (ë³´ì•ˆìƒ ì•ˆì „)
    GEMINI_API_KEY = st.text_input("Gemini API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")
    if not GEMINI_API_KEY:
        st.warning("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œì»¬ ì‹¤í–‰ ì‹œ .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

genai.configure(api_key=GEMINI_API_KEY)
# model = genai.GenerativeModel('gemini-pro') 
model = genai.GenerativeModel('gemini-2.5-flash') # Or gemini-1.5-pro-latest


# Toss ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ CSS (ë‹¨ê³„ë³„ ì§„í–‰ ë°” ë“± ì¶”ê°€)
st.markdown("""
    <style>
    .main { background-color: #F9FAFB; }
    .stButton>button { width: 100%; border-radius: 12px; height: 3em; background-color: #0047FF; color: white; font-weight: bold; border: none; }
    .stProgress > div > div > div > div { background-color: #0047FF; }
    div[data-testid="stExpander"] { background-color: white; border-radius: 10px; border: 1px solid #E5E7EB; }
    </style>
""", unsafe_allow_html=True)

# --- [2. ë„êµ¬ í•¨ìˆ˜ë“¤] ---
def reset_state():
    """ì•± ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    st.session_state.clear()
    st.session_state.step = 'upload'
    st.session_state.current_step_idx = 0
    st.session_state.log = []

def suggest_goals(df):
    """ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¶„ì„ ëª©í‘œ 4ê°€ì§€ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."""
    cols = list(df.columns)
    sample = df.head(3).to_csv(index=False)
    
    prompt = f"""
    Analyze the dataset to propose 4 distinct and meaningful data analysis or machine learning goals.
    Columns: {cols}
    Data Sample: {sample}
    
    Return a valid JSON list of strings (Korean). Each string should be a short, actionable goal title.
    Example output: ["ê³ ê° ì´íƒˆ ì˜ˆì¸¡ (Classification)", "ë§¤ì¶œ ìš”ì¸ ë¶„ì„ (Regression)", "ì‚¬ìš©ì íŒ¨í„´ ì„¸ë¶„í™” (Clustering)", "ì´ìƒ ê±°ë˜ íƒì§€ (Anomaly Detection)"]
    
    Ensure the goals are tailored to the specific context of the data (e.g., if it's Titanic data, mention 'Survival Prediction').
    """
    try:
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        goals = json.loads(text)
        return goals if isinstance(goals, list) else []
    except Exception as e:
        print(f"Goal suggestion error: {e}")
        return ["ë°ì´í„° íƒìƒ‰ (EDA)", "íƒ€ê²Ÿ ë³€ìˆ˜ ì˜ˆì¸¡", "ë°ì´í„° í´ëŸ¬ìŠ¤í„°ë§", "ìƒê´€ê´€ê³„ ë¶„ì„"]

def suggest_target_column(df, goal=""):
    """ë°ì´í„°ì™€ ëª©í‘œë¥¼ ë³´ê³  íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì¶”ì¸¡í•©ë‹ˆë‹¤."""
    # ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ë§Œ ì „ì†¡
    cols = list(df.columns)
    sample = df.head(3).to_csv(index=False)
    
    prompt = f"""
    Analyze the dataset columns and user goal to identify the most likely Target Column (Label) for Machine Learning.
    Columns: {cols}
    User Goal: {goal}
    Data Sample: {sample}
    
    Return ONLY the exact column name of the most likely target. If unsure, return the last column name.
    Do not add any explanation or quotes.
    """
    try:
        response = model.generate_content(prompt)
        suggested_col = response.text.strip().strip("'").strip('"')
        if suggested_col in df.columns:
            return suggested_col
        else:
            return df.columns[-1]
    except:
        return df.columns[-1]

def get_agent_plan(df, goal, target_col, mode="ML"):
    """Geminiê°€ ì „ì²´ ì „ì²˜ë¦¬ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤ (ëª¨ë“œë³„ ì°¨ë³„í™”)."""
    sample_data = df.head(5).to_csv(index=False)
    null_info = df.isnull().mean().to_dict()
    column_types = df.dtypes.astype(str).to_dict()
    unique_counts = df.nunique().to_dict()
    
    # ëª¨ë“œë³„ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
    if "ë¨¸ì‹ ëŸ¬ë‹" in mode:
        role_desc = "Machine Learning Data Engineer"
        focus = "Prepare data for Model Training (One-Hot, Scaling, Imputation)."
        rule_cat = "Categorical columns MUST be encoded (OneHot or Label)."
        rule_target = f"Target '{target_col}' should be Label Encoded if categorical, or passed if numeric."
    else:
        role_desc = "Data Analyst (EDA Expert)"
        focus = "Clean data for Business Insight & Visualization."
        rule_cat = "Categorical columns can be kept as is or simplifed (e.g. Fillna). Encoding is optional."
        rule_target = f"Target '{target_col}' is the key metric. Ensure it is clean."

    prompt = f"""
    You are a {role_desc}.
    Goal: {goal}
    Target: {target_col}
    Mode: {mode} ({focus})
    
    Data Context:
    - Sample: {sample_data}
    - Null Ratios: {null_info}
    - Types: {column_types}
    - Unique Counts: {unique_counts}
    
    Task: Propose a step-by-step plan for each column.
    Available Actions: [Drop, Fill_Median, Fill_Mode, Fill_Zero, Normalize, Encode_OneHot, Encode_Label, Pass]
    
    Rules ({mode}):
    1. {rule_cat}
    2. {rule_target}
    3. Return a valid JSON list.
    
    [
        {{"col": "column_name", "action": "Selected Action", "reason": "Reason (Korean)"}}
    ]
    """
    try:
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except Exception as e:
        print(f"Error calling Gemini: {e}") 
        return [{"col": c, "action": "Pass", "reason": f"API ì˜¤ë¥˜ë¡œ ê¸°ë³¸ Pass ì²˜ë¦¬ ({str(e)})"} for c in df.columns]

def apply_step(df, col, action):
    """ë‹¨ì¼ ìŠ¤í…(ì»¬ëŸ¼ ì•¡ì…˜)ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    new_df = df.copy()
    
    if col not in new_df.columns:
        return new_df

    try:
        if action == "Drop":
            new_df = new_df.drop(columns=[col])
        elif action == "Fill_Median":
            if pd.api.types.is_numeric_dtype(new_df[col]):
                val = new_df[col].median()
                new_df[col] = new_df[col].fillna(val)
        elif action == "Fill_Mode":
            val = new_df[col].mode()[0]
            new_df[col] = new_df[col].fillna(val)
        elif action == "Fill_Zero":
            new_df[col] = new_df[col].fillna(0)
        elif action == "Normalize":
            if pd.api.types.is_numeric_dtype(new_df[col]):
                scaler = StandardScaler()
                data = new_df[[col]].values
                new_df[col] = scaler.fit_transform(data).flatten()
        elif action == "Encode_Label":
            le = LabelEncoder()
            # ê²°ì¸¡ì¹˜ëŠ” ì„ì‹œ ì²˜ë¦¬ í›„ ì¸ì½”ë”©
            new_df[col] = new_df[col].fillna("Unknown").astype(str)
            new_df[col] = le.fit_transform(new_df[col])
        elif action == "Encode_OneHot":
            # One-Hotì€ ì»¬ëŸ¼ì´ ëŠ˜ì–´ë‚˜ë¯€ë¡œ ì²˜ë¦¬ê°€ ì¡°ê¸ˆ ë‹¤ë¦…ë‹ˆë‹¤.
            # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” í•´ë‹¹ ì»¬ëŸ¼ì„ ì›í•« ì¸ì½”ë”©í•œ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.
            dummies = pd.get_dummies(new_df[col], prefix=col, drop_first=False)
            new_df = pd.concat([new_df.drop(columns=[col]), dummies], axis=1)
            
    except Exception as e:
        st.error(f"Action '{action}' failed on '{col}': {e}")
            
    return new_df

def plot_comparison(old_df, new_df, col):
    """ë³€ê²½ ì „í›„ ë¶„í¬ ë¹„êµ ì‹œê°í™” (Plotly)"""
    # 1. ì»¬ëŸ¼ì´ ì‚¬ë¼ì§„ ê²½ìš° (Drop, OneHot ë“±)
    if col not in new_df.columns:
        st.info(f"â„¹ï¸ '{col}' ì»¬ëŸ¼ì€ ì²˜ë¦¬ í›„ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ì˜ˆ: One-Hot Encoding)")
        return

    col_c1, col_c2 = st.columns(2)
    
    # 2. ìˆ˜ì¹˜í˜• ë°ì´í„° ì‹œê°í™”
    if pd.api.types.is_numeric_dtype(new_df[col]):
        with col_c1:
            # Histogram
            fig = go.Figure()
            # Original
            fig.add_trace(go.Histogram(x=old_df[col].dropna(), name='Original', opacity=0.5, marker_color='gray'))
            # Transformed
            fig.add_trace(go.Histogram(x=new_df[col], name='Transformed', opacity=0.5, marker_color='blue'))
            fig.update_layout(title_text=f"{col} Distribution (Histogram)", barmode='overlay')
            st.plotly_chart(fig, use_container_width=True)
            
        with col_c2:
            # Box Plot
            fig2 = go.Figure()
            fig2.add_trace(go.Box(y=old_df[col].dropna(), name='Original', marker_color='gray'))
            fig2.add_trace(go.Box(y=new_df[col], name='Transformed', marker_color='blue'))
            fig2.update_layout(title_text=f"{col} Box Plot (Outliers)")
            st.plotly_chart(fig2, use_container_width=True)

        st.markdown("#### ğŸ”¢ í†µê³„ ìš”ì•½")
        desc_old = old_df[col].describe()
        desc_new = new_df[col].describe()
        stats_df = pd.DataFrame({'Original': desc_old, 'Transformed': desc_new})
        st.dataframe(stats_df.T, use_container_width=True)

    # 3. ë²”ì£¼í˜• ë°ì´í„° ì‹œê°í™”
    else:
        # ìƒìœ„ 10ê°œ ì¹´í…Œê³ ë¦¬
        top_n = 10
        old_counts = old_df[col].value_counts().head(top_n)
        new_counts = new_df[col].value_counts().head(top_n)
        
        with col_c1:
            fig = px.bar(x=old_counts.index, y=old_counts.values, title=f"Original Top {top_n}", labels={'x':'Category', 'y':'Count'})
            st.plotly_chart(fig, use_container_width=True)
            
        with col_c2:
            fig2 = px.bar(x=new_counts.index, y=new_counts.values, title=f"Transformed Top {top_n}", labels={'x':'Category', 'y':'Count'})
            st.plotly_chart(fig2, use_container_width=True)

# --- [3. ë©”ì¸ ë¡œì§] ---
if 'step' not in st.session_state:
    st.session_state.step = 'upload'
    st.session_state.current_step_idx = 0
    st.session_state.log = [] 

# --- [Image Mode Logic] ---
def run_image_mode():
    st.header("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ (Image Preprocessing)")
    
    with st.expander("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ", expanded=True):
        st.write("""
        1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: ì²˜ë¦¬ë¥¼ ì›í•˜ëŠ” ì´ë¯¸ì§€ë“¤ì„ í•œêº¼ë²ˆì— ì—…ë¡œë“œí•˜ì„¸ìš”.
        2. **ì˜µì…˜ ì„¤ì •**: ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸°, í‘ë°± ë³€í™˜, ì •ê·œí™” ì—¬ë¶€ë¥¼ ì„ íƒí•˜ì„¸ìš”.
        3. **ë³€í™˜ ë° ë‹¤ìš´ë¡œë“œ**: PyTorch Tensor `(N, C, H, W)` í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ `.pt` íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
        """)
        
    uploaded_files = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (JPG, PNG, WEBP)", type=['jpg', 'jpeg', 'png', 'webp'], accept_multiple_files=True)
    
    if uploaded_files:
        st.markdown("### âš™ï¸ ì „ì²˜ë¦¬ ì˜µì…˜")
        c1, c2, c3 = st.columns(3)
        target_size = c1.number_input("Resize Size (Square)", min_value=32, value=224, step=32)
        grayscale = c2.checkbox("Grayscale ë³€í™˜", value=False)
        normalize = c3.checkbox("Normalize (0~1 Scaling)", value=True)
        
        st.markdown("---")
        st.subheader("ğŸ‘€ ë¯¸ë¦¬ë³´ê¸° (First 5 Images)")
        
        from PIL import Image
        import torchvision.transforms as T
        
        # Define Transform
        transforms_list = []
        transforms_list.append(T.Resize((target_size, target_size)))
        if grayscale:
            transforms_list.append(T.Grayscale(num_output_channels=1))
        transforms_list.append(T.ToTensor())
        # Note: ToTensor converts [0, 255] -> [0.0, 1.0] implicitly.
        # If user wants 0~1 scaling, ToTensor does it.
        # If user DOES NOT want it (wants 0-255), we might need to multiply by 255? 
        # Usually Tensor is float 0-1. Let's stick to standard ToTensor.
        
        transform = T.Compose(transforms_list)
        
        preview_cols = st.columns(5)
        processed_tensors = []
        
        for i, file in enumerate(uploaded_files):
            try:
                img = Image.open(file).convert('RGB')
                
                # Preview Original
                if i < 5:
                    with preview_cols[i]:
                        st.image(img, caption=f"Original {i+1}", use_container_width=True)
                
                # Process
                tensor = transform(img) # [C, H, W]
                processed_tensors.append(tensor)
                
            except Exception as e:
                st.error(f"{file.name} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

        if processed_tensors:
            # Stack: [N, C, H, W]
            batch_tensor = torch.stack(processed_tensors)
            
            st.success(f"âœ… ì´ {len(batch_tensor)}ì¥ ë³€í™˜ ì™„ë£Œ! Shape: {batch_tensor.shape}")
            
            # Save
            buffer = io.BytesIO()
            torch.save(batch_tensor, buffer)
            st.download_button("ğŸ’¾ Download images.pt", buffer.getvalue(), "images.pt")

# --- [Main Layout Control] ---

# Sidebar Control
with st.sidebar:
    st.title("ğŸ›ï¸ Mode Selection")
    mode = st.selectbox("Data Type", ["Tabular Data (CSV/Excel)", "Image Data (JPG/PNG)"])
    
    st.markdown("---")
    
    # [Image Mode Entry Point]
    if mode == "Image Data (JPG/PNG)":
        run_image_mode()
        st.stop() # Stop further execution for Tabular mode

    # [Tabular Mode Continued...]
    st.header("ğŸ”§ Tabular Controls")
    
    # 1. Reset Button (Always accessible)
    if st.button("ğŸ”„ Start Over (Reset)", type="primary", use_container_width=True):
        reset_state()
        st.rerun()
    
    st.markdown("---")
    
    # 2. Progress Tracker
    steps = ["upload", "plan_edit", "execute_loop", "final"]
    step_labels = ["1. Upload & Goal", "2. Plan Review", "3. Processing", "4. Download"]
    
    current_idx = 0
    if st.session_state.step in steps:
        current_idx = steps.index(st.session_state.step)
    
    st.caption("ï¿½ Current Progress")
    # Custom progress visualization using radio (disabled) to act as a stepper
    st.radio(
        "Steps", 
        step_labels, 
        index=current_idx, 
        disabled=True,
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    
    # 3. Data Summary (Active Monitor)
    if 'df' in st.session_state:
        st.subheader("ğŸ“Š Data Status")
        n_rows, n_cols = st.session_state.df.shape
        st.write(f"**Rows:** {n_rows:,}")
        st.write(f"**Columns:** {n_cols}")
        
        if 'target_col' in st.session_state:
            st.write(f"**Target:** `{st.session_state.target_col}`")
            
        if 'goal' in st.session_state:
            with st.expander("Target Goal"):
                st.write(st.session_state.goal)
    
    # 4. Context Help
    st.markdown("---")
    with st.expander("ğŸ’¡ Tip / Help", expanded=True):
        if st.session_state.step == 'upload':
            st.info("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ ëª©í‘œë¥¼ ì„¤ì •í•˜ì„¸ìš”. AIê°€ ìë™ìœ¼ë¡œ ìµœì ì˜ íƒ€ê²Ÿì„ ì°¾ìŠµë‹ˆë‹¤.")
        elif st.session_state.step == 'plan_edit':
            st.info("AIê°€ ì œì•ˆí•œ ì „ì²˜ë¦¬ ê³„íšì„ ê²€í† í•˜ì„¸ìš”. í•„ìš”í•˜ë‹¤ë©´ ì•¡ì…˜ì„ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif st.session_state.step == 'execute_loop':
            st.info("ë‹¨ê³„ë³„ë¡œ ë°ì´í„° ë³€í™”ë¥¼ í™•ì¸í•˜ë©° ì§„í–‰í•˜ì„¸ìš”. 'Apply'ë¥¼ ëˆ„ë¥´ë©´ ì €ì¥ë©ë‹ˆë‹¤.")
        elif st.session_state.step == 'final':
            st.info("ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.")

    st.caption("v1.3 - Enhanced Sidebar")
if st.session_state.step == 'upload':
    st.subheader("1. ë°ì´í„° & ëª©í‘œ ì„¤ì •")
    uploaded_files = st.file_uploader(
        "ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (CSV, Excel, JSON, Parquet supported)", 
        type=['csv', 'xlsx', 'xls', 'json', 'parquet'],
        accept_multiple_files=True
    )
    
    temp_df = None
    dataset_name = ""

    if uploaded_files:
        # 1. íŒŒì¼ ë¡œë”©
        loaded_dfs = {}
        for f in uploaded_files:
            try:
                if f.name.endswith('.csv'):
                    loaded_dfs[f.name] = pd.read_csv(f)
                elif f.name.endswith(('.xlsx', '.xls')):
                    loaded_dfs[f.name] = pd.read_excel(f)
                elif f.name.endswith('.json'):
                    loaded_dfs[f.name] = pd.read_json(f)
                elif f.name.endswith('.parquet'):
                    loaded_dfs[f.name] = pd.read_parquet(f)
            except Exception as e:
                st.error(f"âŒ '{f.name}' ë¡œë“œ ì‹¤íŒ¨: {e}")

        # 2. ë³‘í•© ë¡œì§ (íŒŒì¼ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš°)
        if len(loaded_dfs) > 1:
            st.info(f"ğŸ“‚ {len(loaded_dfs)}ê°œì˜ íŒŒì¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë³‘í•© ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”.")
            
            with st.expander("ğŸ§© ë°ì´í„° ë³‘í•© ì„¤ì • (Data Merger)", expanded=True):
                merge_type = st.radio("ë³‘í•© ë°©ì‹", ["Vertical (Concat) - ìœ„ì•„ë˜ë¡œ í•©ì¹˜ê¸°", "Horizontal (Merge) - ì˜†ìœ¼ë¡œ í•©ì¹˜ê¸° (Key ê¸°ì¤€)"])
                
                if "Vertical" in merge_type:
                    st.caption("ëª¨ë“  íŒŒì¼ì˜ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì•„ë˜ë¡œ í•©ì¹©ë‹ˆë‹¤. (ì»¬ëŸ¼ëª…ì´ ê°™ì•„ì•¼ í•¨)")
                    if st.button("Vertical Concat ì‹¤í–‰"):
                        try:
                            temp_df = pd.concat(loaded_dfs.values(), axis=0, ignore_index=True)
                            dataset_name = f"Merged_{len(loaded_dfs)}_Files_Concat"
                            st.success(f"âœ… ë³‘í•© ì™„ë£Œ! ì´ {len(temp_df)}í–‰")
                        except Exception as e:
                            st.error(f"ë³‘í•© ì‹¤íŒ¨: {e}")
                else:
                    st.caption("ë‘ ê°œì˜ íŒŒì¼ì„ ê³µí†µ ì»¬ëŸ¼(Key) ê¸°ì¤€ìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤. (í˜„ì¬ëŠ” 2ê°œ íŒŒì¼ ë³‘í•©ë§Œ ì§€ì›)")
                    file_names = list(loaded_dfs.keys())
                    c1, c2 = st.columns(2)
                    left_name = c1.selectbox("Left Data", file_names)
                    right_name = c2.selectbox("Right Data", [n for n in file_names if n != left_name])
                    
                    left_df = loaded_dfs[left_name]
                    right_df = loaded_dfs[right_name]
                    
                    # ê³µí†µ ì»¬ëŸ¼ ì°¾ê¸°
                    common_cols = list(set(left_df.columns) & set(right_df.columns))
                    key_col = st.selectbox("Key Column (Join Key)", common_cols if common_cols else left_df.columns)
                    
                    if st.button("Horizontal Merge ì‹¤í–‰"):
                        try:
                            temp_df = pd.merge(left_df, right_df, on=key_col, how='inner')
                            dataset_name = f"Merged_{left_name}_{right_name}"
                            st.success(f"âœ… ë³‘í•© ì™„ë£Œ! ì´ {len(temp_df)}í–‰ (Inner Join on {key_col})")
                        except Exception as e:
                            st.error(f"ë³‘í•© ì‹¤íŒ¨: {e}")

        # 3. ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš°
        elif len(loaded_dfs) == 1:
            name = list(loaded_dfs.keys())[0]
            temp_df = loaded_dfs[name]
            dataset_name = name

    if temp_df is not None:
        # AI Cache Logic Update (Use dataset_name instead of uploaded_file.name)
        # âš ï¸ Large Data Handling (Smart Sampling)

        if len(temp_df) > 10000:
            st.warning(f"âš ï¸ ë°ì´í„°ê°€ ê½¤ í½ë‹ˆë‹¤ ({len(temp_df):,} Rows).")
            use_sample = st.checkbox("ğŸš€ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ 10% ìƒ˜í”Œë§ ì‚¬ìš© (ê¶Œì¥)", value=True)
            if use_sample:
                temp_df = temp_df.sample(frac=0.1, random_state=42)
                st.success(f"âœ… ìƒ˜í”Œë§ ì ìš©ë¨: {len(temp_df):,} Rowsë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        
        # --- [Advanced EDA Tabs] ---
        st.markdown("### ğŸ” Advanced Data Analysis (EDA)")
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“„ Data Preview", "ğŸ“Š Distribution", "ğŸ“‰ Missing Values", "ğŸ”¥ Correlation", "ğŸ“¦ Outliers"])
        
        with tab1:
            st.dataframe(temp_df.head(5))
            st.caption(f"Total Shape: {temp_df.shape}")

        with tab2:
            st.subheader("Numeric Distribution")
            numeric_cols = temp_df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                selected_dist_col = st.selectbox("Select Column to Visualize", numeric_cols, key="dist_col")
                fig_dist = px.histogram(temp_df, x=selected_dist_col, marginal="box", title=f"Distribution of {selected_dist_col}")
                st.plotly_chart(fig_dist, use_container_width=True)
            else:
                st.info("No numeric columns found.")

        with tab3:
            st.subheader("Missing Values Analysis")
            missing = temp_df.isnull().sum()
            missing = missing[missing > 0]
            if not missing.empty:
                fig_miss = px.bar(x=missing.index, y=missing.values, labels={'x': 'Column', 'y': 'Missing Count'}, title="Missing Values per Column")
                st.plotly_chart(fig_miss, use_container_width=True)
            else:
                st.success("âœ¨ ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ” ë°ì´í„°ì…ë‹ˆë‹¤! (No missing values)")

        with tab4:
            st.subheader("Correlation Heatmap")
            numeric_df = temp_df.select_dtypes(include=[np.number])
            if numeric_df.shape[1] > 1:
                try:
                    corr = numeric_df.corr()
                    fig_corr = px.imshow(corr, text_auto=True, color_continuous_scale='RdBu_r', aspect='auto')
                    st.plotly_chart(fig_corr, use_container_width=True)
                except:
                    st.warning("ìƒê´€ê´€ê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            else:
                st.info("ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")

        with tab5:
            st.subheader("Outlier Detection (Box Plot)")
            if len(numeric_cols) > 0:
                selected_box_col = st.selectbox("Select Column for Box Plot", numeric_cols, key="box_col")
                fig_box = px.box(temp_df, y=selected_box_col, title=f"Box Plot of {selected_box_col}")
                st.plotly_chart(fig_box, use_container_width=True)
            else:
                st.info("No numeric columns.")
        
        if 'last_uploaded_file' not in st.session_state or st.session_state.last_uploaded_file != dataset_name:
            st.session_state.last_uploaded_file = dataset_name
            st.session_state.ai_goals = [] # Reset goals
            
            with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¶„ì„ ëª©í‘œë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤... ğŸ•µï¸â€â™€ï¸"):
                st.session_state.ai_goals = suggest_goals(temp_df)
        
        st.markdown("---")
        st.subheader("ğŸ¯ ë¶„ì„ ëª©í‘œ ì„¤ì •")
        
        col_mode, col_goal = st.columns([1, 2])
        
        with col_mode:
            analysis_mode = st.radio(
                "ë¶„ì„ ëª¨ë“œ ì„ íƒ",
                ["ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµìš© ì „ì²˜ë¦¬", "ì¼ë°˜ ë°ì´í„° ë¶„ì„(EDA)"],
                captions=["ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ Feature Engineering", "ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ë° ì‹œê°í™”"]
            )
        
        with col_goal:
            # ì¶”ì²œ ëª©í‘œ ì œì•ˆ (Pills)
            st.write(f"ğŸ’¡ AI ë§ì¶¤ ì¶”ì²œ ({dataset_name}):")
            
            # AIê°€ ì œì•ˆí•œ ëª©í‘œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            example_goals = st.session_state.get('ai_goals', ["ë°ì´í„° íƒìƒ‰ (EDA)", "ì˜ˆì¸¡ ë¶„ì„"])
            
            # Session Stateë¥¼ ì´ìš©í•´ í…ìŠ¤íŠ¸ ì…ë ¥ê°’ ì œì–´
            if "user_goal_input" not in st.session_state:
                st.session_state.user_goal_input = ""
            
            # 2x2 ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
            cols_ex = st.columns(2)
            for idx, ex in enumerate(example_goals):
                if cols_ex[idx % 2].button(ex, key=f"ex_btn_{idx}", use_container_width=True):
                    st.session_state.user_goal_input = ex
            
            user_goal = st.text_input(
                "ëª©í‘œë¥¼ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ìœ„ AI ì¶”ì²œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.", 
                value=st.session_state.user_goal_input, 
                placeholder="ì˜ˆ: ì´ ë°ì´í„°ë¡œ í•  ìˆ˜ ìˆëŠ” ê°€ì¥ í¥ë¯¸ë¡œìš´ ë¶„ì„ì€?"
            )

        # ëª©í‘œê°€ ì…ë ¥ë˜ë©´ íƒ€ê²Ÿ ì¶”ì²œ ì‹¤í–‰
        if user_goal:
            # ëª©í‘œë‚˜ íŒŒì¼ì´ ë°”ë€Œì—ˆì„ ë•Œë§Œ ì¬ì‹¤í–‰
            current_context = f"{dataset_name}_{user_goal}"
            if 'last_context' not in st.session_state or st.session_state.last_context != current_context:
                st.session_state.last_context = current_context
                
                with st.spinner("ëª©í‘œì— ë§ì¶° ê°€ì¥ ì ì ˆí•œ íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì°¾ëŠ” ì¤‘..."):
                    suggested = suggest_target_column(temp_df, user_goal)
                    st.session_state.suggested_target = suggested
                    st.toast(f"AI ì¶”ì²œ: '{suggested}' ì»¬ëŸ¼ì„ íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.", icon="ğŸ¯")
            
            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì„ íƒ UI
            col_list = list(temp_df.columns)
            default_idx = 0
            if 'suggested_target' in st.session_state and st.session_state.suggested_target in col_list:
                default_idx = col_list.index(st.session_state.suggested_target)
                
            target_col = st.selectbox(
                "ğŸ¯ íƒ€ê²Ÿ ì»¬ëŸ¼(ì •ë‹µì§€) í™•ì¸ ë° ë³€ê²½", 
                col_list, 
                index=default_idx,
                help="ëª¨ë¸ì´ ì˜ˆì¸¡í•´ì•¼ í•  ìµœì¢… ëª©í‘œ ë³€ìˆ˜ì…ë‹ˆë‹¤."
            )
            
            st.markdown("---")
            if st.button("AIì—ê²Œ ê³„íš ìš”ì²­í•˜ê¸° ğŸš€", type="primary", disabled=(not user_goal)):
                # ì‚¬ìš©ìê°€ ìµœì¢… ì„ íƒí•œ ëª©í‘œ ì €ì¥
                st.session_state.goal = user_goal
                st.session_state.target_col = target_col
                
                with st.spinner("AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì „ì²˜ë¦¬ ê³„íšì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ§ "):
                    # Pass the selected analysis mode
                    plan = get_agent_plan(temp_df, user_goal, target_col, mode=analysis_mode)
                    st.session_state.plan = plan
                    st.session_state.df = temp_df # ì´ˆê¸° ë°ì´í„° ì €ì¥
                    st.session_state.step = 'plan_edit'
                    st.rerun()

# [Step 2] ê³„íš ê²€í†  ë° ìˆ˜ì • (Plan Editor)
elif st.session_state.step == 'plan_edit':
    st.subheader("2. AI ì œì•ˆ ì „ì²˜ë¦¬ ê³„íš ê²€í† ")
    st.info("AIê°€ ì œì•ˆí•œ ê³„íšì…ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ -> DataFrame ë³€í™˜
    plan_df = pd.DataFrame(st.session_state.plan)
    
    # ìˆ˜ì • ê°€ëŠ¥í•œ Data Editor
    edited_plan_df = st.data_editor(
        plan_df,
        column_config={
            "col": st.column_config.TextColumn("ì»¬ëŸ¼ëª…", disabled=True),
            "action": st.column_config.SelectboxColumn(
                "ì•¡ì…˜",
                options=["Pass", "Drop", "Fill_Median", "Fill_Mode", "Fill_Zero", "Normalize", "Encode_Label", "Encode_OneHot"],
                required=True
            ),
            "reason": st.column_config.TextColumn("ì´ìœ  (AI ìƒì„±)", disabled=True)
        },
        use_container_width=True,
        hide_index=True,
        num_rows="fixed"
    )
    
    col1, col2 = st.columns(2)
    if col1.button("ì´ëŒ€ë¡œ ì‹¤í–‰í•˜ê¸° â–¶ï¸", type="primary"):
        # ìˆ˜ì •ëœ ë‚´ìš©ì„ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        st.session_state.plan = edited_plan_df.to_dict('records')
        st.session_state.history = []  # Initialize history tracking
        st.session_state.step = 'execute_loop'
        st.rerun()
        
    if col2.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.session_state.step = 'upload'
        st.rerun()

# [Step 3] ì‹¤í–‰ ë£¨í”„
elif st.session_state.step == 'execute_loop':
    # --- [New Feature] Custom Code Execution ---
    with st.expander("ğŸ› ï¸ Advanced: Execute Custom Python Code"):
        st.caption("í˜„ì¬ ë°ì´í„°í”„ë ˆì„(`df`)ì— ì§ì ‘ íŒŒì´ì¬ ì½”ë“œë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆ: `df['new'] = df['a'] + df['b']`")
        custom_code = st.text_area("Python Code", height=100)
        if st.button("Run Custom Code"):
            try:
                local_scope = {'df': st.session_state.df, 'pd': pd, 'np': np}
                exec(custom_code, globals(), local_scope)
                st.session_state.df = local_scope['df']
                st.success("Custom code executed successfully!")
                st.session_state.log.append("User executed custom code.")
                st.rerun()
            except Exception as e:
                st.error(f"Error: {e}")

    plan = st.session_state.plan
    idx = st.session_state.current_step_idx
    
    if idx < len(plan):
        current_item = plan[idx]
        col = current_item['col']
        action = current_item['action']
        reason = current_item['reason']
        
        # ì´ë¯¸ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ì»¬ëŸ¼ì´ ì‚¬ë¼ì¡Œì„ ìˆ˜ë„ ìˆìŒ (ì˜ˆ: ì´ì „ ë‹¨ê³„ì˜ OneHot ë“±)
        # í•˜ì§€ë§Œ ì›ë³¸ ì»¬ëŸ¼ëª… ê¸°ì¤€ ë£¨í”„ì´ë¯€ë¡œ, í˜„ì¬ dfì— colì´ ìˆëŠ”ì§€ ì²´í¬ í•„ìš”
        col_exists = col in st.session_state.df.columns
        
        progress = (idx / len(plan))
        st.progress(progress, text=f"Processing... ({int(progress*100)}%)")
        
        st.subheader(f"Step {idx+1}/{len(plan)}: {col}")
        
        if not col_exists:
            st.warning(f"âš ï¸ ì»¬ëŸ¼ '{col}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ë³€í˜•ë¨)")
            # ìë™ ìŠ¤í‚µ
            if st.button("ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ê¸°"):
                st.session_state.log.append(f"Step {idx+1}: {col} -> Skipped (Not Found)")
                st.session_state.current_step_idx += 1
                st.rerun()
            st.stop()

        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.markdown(f"**{col}** â†’ **`{action}`**")
            st.caption(f"Reason: {reason}")

        # Preview
        preview_df = apply_step(st.session_state.df, col, action)
        
        with st.expander("ğŸ” ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (Interactive Chart)", expanded=True):
            if action != "Drop":
                plot_comparison(st.session_state.df, preview_df, col)
            else:
                st.error(f"ğŸ—‘ï¸ '{col}' ì»¬ëŸ¼ì´ ì œê±°ë©ë‹ˆë‹¤.")

        st.write("---")
        c1, c2, c3 = st.columns(3)
        if c1.button("âœ… ìŠ¹ì¸ (Apply)", type="primary", use_container_width=True):
            st.session_state.history.append(st.session_state.df.copy())
            st.session_state.df = preview_df
            st.session_state.log.append(f"{col}: {action}")
            st.session_state.current_step_idx += 1
            st.rerun()
            
        if c2.button("âŒ ê±´ë„ˆë›°ê¸° (Pass)", use_container_width=True):
            st.session_state.history.append(st.session_state.df.copy())
            # df ë³€ê²½ ì—†ìŒ
            st.session_state.log.append(f"{col}: Pass (User Skipped)")
            st.session_state.current_step_idx += 1
            st.rerun()
            
        if c3.button("â†©ï¸ ì‹¤í–‰ ì·¨ì†Œ (Undo)", use_container_width=True):
            if st.session_state.history:
                st.session_state.df = st.session_state.history.pop()
                if st.session_state.log: st.session_state.log.pop()
                st.session_state.current_step_idx -= 1
                st.rerun()
            else:
                st.warning("ëŒì•„ê°ˆ ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        if st.button("â© ë‚¨ì€ ë‹¨ê³„ ì¼ê´„ ìŠ¹ì¸ (Apply All Remaining)", type="secondary", use_container_width=True):
            with st.spinner("ë‚¨ì€ ëª¨ë“  ë‹¨ê³„ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                # í˜„ì¬ ë‹¨ê³„ë¶€í„° ëê¹Œì§€ ë£¨í”„
                current_plan = st.session_state.plan
                start_idx = st.session_state.current_step_idx
                
                # Undoë¥¼ ìœ„í•œ ìŠ¤ëƒ…ìƒ· ì €ì¥ (í•œ ë²ˆë§Œ ì €ì¥í•˜ì—¬ ì „ì²´ ì·¨ì†Œ ê°€ëŠ¥í•˜ê²Œ í•˜ê±°ë‚˜, ë‹¨ê³„ë³„ë¡œ í•˜ê±°ë‚˜. ê°„ë‹¨íˆ ì—¬ê¸°ì„  ë§ˆì§€ë§‰ ìƒíƒœë¡œ ì í”„)
                # ë³µì¡í•˜ë¯€ë¡œ historyì— í˜„ì¬ ìƒíƒœ í•˜ë‚˜ëŠ” ì €ì¥í•´ë‘ì
                st.session_state.history.append(st.session_state.df.copy())

                for i in range(start_idx, len(current_plan)):
                    item = current_plan[i]
                    p_col = item['col']
                    p_act = item['action']
                    
                    # ì‹¤í–‰
                    st.session_state.df = apply_step(st.session_state.df, p_col, p_act)
                    st.session_state.log.append(f"{p_col}: {p_act} (Batch Applied)")
                
                # ëìœ¼ë¡œ ì´ë™
                st.session_state.current_step_idx = len(current_plan)
                st.rerun()

    else:
        st.session_state.step = 'final'
        st.rerun()

# [Step 4] ì™„ë£Œ ë° ë‹¤ìš´ë¡œë“œ
elif st.session_state.step == 'final':
    st.balloons()
    st.success("ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    final_df = st.session_state.df
    target_col = st.session_state.target_col
    
    st.subheader("ğŸ“Š ìµœì¢… ë°ì´í„° ìš”ì•½")
    st.dataframe(final_df.head())
    st.write(f"Shape: {final_df.shape}")
    
    with st.expander("ï¿½ï¸ ì²˜ë¦¬ ë¡œê·¸"):
        for l in st.session_state.log:
            st.text(l)
            
    # --- Report Generator ---
    st.subheader("0. ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± (Report)")
    if st.button("Generate HTML Report ğŸ“„"):
        report_html = generate_html_report(
            df_info=str(final_df.shape),
            goal=st.session_state.get('goal', 'N/A'),
            target=target_col,
            plan=st.session_state.plan,
            logs=st.session_state.log,
            metrics="AutoML not run yet."
        )
        st.download_button("ğŸ’¾ Download Report (.html)", report_html, "report.html", mime="text/html")
        
    st.markdown("---")
    
    # --- Code Generator ---
    st.subheader("1. ğŸ“œ íŒŒì´ì¬ ì½”ë“œ ìƒì„± (Code Generator)")
    
    script_type = st.radio("Script Engine", ["Pandas (Standard)", "Dask (Big Data > 10GB)"], horizontal=True)
    
    if st.button("Generate Python Code ğŸ"):
        if "Dask" in script_type:
            st.session_state.gen_code = generate_dask_code(st.session_state.plan, target_col)
            st.session_state.gen_filename = "preprocessing_dask.py"
        else:
            st.session_state.gen_code = generate_python_code(st.session_state.plan, target_col)
            st.session_state.gen_filename = "preprocessing_pandas.py"
            
    if st.session_state.get("gen_code"):
        st.code(st.session_state.gen_code, language='python')
        st.download_button("ğŸ’¾ Download .py", st.session_state.gen_code, st.session_state.gen_filename)

    # --- AutoML ---
    st.markdown("---")
    st.subheader("2. ğŸ¤– AutoML Baseline")
    if st.button("Run AutoML Training ğŸš€"):
        try:
             # Data Prep (Simplified - Reuse logic)
             if target_col in final_df.columns:
                 y_tmp = final_df[target_col]
                 X_tmp = final_df.drop(columns=[target_col])
             else:
                 target_cols = [c for c in final_df.columns if str(c).startswith(f"{target_col}_")]
                 if target_cols:
                     y_tmp = final_df[target_cols]
                     X_tmp = final_df.drop(columns=target_cols)
                 else:
                     st.error("Target missing.")
                     X_tmp = final_df
                     y_tmp = np.empty(len(final_df))

             # Numeric Cleaning
             X_tmp = X_tmp.apply(pd.to_numeric, errors='coerce').fillna(0)
             X_tmp = X_tmp.select_dtypes(include=[np.number])

             # Y Cleaning & Task Inference
             if isinstance(y_tmp, pd.DataFrame):
                 y_tmp = y_tmp.apply(pd.to_numeric, errors='coerce').fillna(0).values
                 if y_tmp.shape[1] > 1: y_tmp = np.argmax(y_tmp, axis=1)
             else:
                 y_tmp = pd.to_numeric(y_tmp, errors='coerce').fillna(0).values
             
             unique_y = len(np.unique(y_tmp))
             # Heuristic: < 20 classes or non-float => Classification
             is_clf = unique_y < 20 or (not np.issubdtype(y_tmp.dtype, np.floating))

             # Imports
             from sklearn.model_selection import train_test_split
             from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor
             from sklearn.linear_model import LogisticRegression, Ridge
             from sklearn.metrics import accuracy_score, r2_score, f1_score, mean_absolute_error
             import time
             
             X_tr, X_te, y_tr, y_te = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=42)
             
             models = []
             if is_clf:
                 task_name = "Classification"
                 metric_name = "Accuracy"
                 models = [
                     ("Logistic Regression", LogisticRegression(max_iter=500)),
                     ("Random Forest", RandomForestClassifier(n_estimators=50, random_state=42)),
                     ("Gradient Boosting", GradientBoostingClassifier(n_estimators=50, random_state=42))
                 ]
             else:
                 task_name = "Regression"
                 metric_name = "R2 Score"
                 models = [
                     ("Ridge Regression", Ridge()),
                     ("Random Forest", RandomForestRegressor(n_estimators=50, random_state=42)),
                     ("Gradient Boosting", GradientBoostingRegressor(n_estimators=50, random_state=42))
                 ]
             
             st.write(f"### ğŸ AutoML Race ({task_name})")
             results = []
             best_model = None
             best_score = -9999
             best_model_name = ""

             progress_bar = st.progress(0)
             
             for i, (name, model) in enumerate(models):
                 start_t = time.time()
                 model.fit(X_tr, y_tr)
                 train_time = time.time() - start_t
                 
                 score = model.score(X_te, y_te) 
                 # For additional metrics if needed
                 # if is_clf: extra = f1_score(y_te, model.predict(X_te), average='weighted')
                 
                 results.append({
                     "Model": name, 
                     metric_name: round(score, 4), 
                     "Time (s)": round(train_time, 3)
                 })
                 
                 if score > best_score:
                     best_score = score
                     best_model = model
                     best_model_name = name
                     
                 progress_bar.progress((i + 1) / len(models))

             # Leaderboard
             res_df = pd.DataFrame(results).sort_values(by=metric_name, ascending=False)
             st.success(f"ğŸ† Winner: **{best_model_name}** ({metric_name}: {best_score:.4f})")
             
             c1, c2 = st.columns([2, 1])
             with c1:
                 st.dataframe(res_df, use_container_width=True, hide_index=True)
             with c2:
                 st.plotly_chart(px.bar(res_df, x='Model', y=metric_name, color='Model', title="Score Comparison"), use_container_width=True)
             
             # Feature Importance
             if hasattr(best_model, 'feature_importances_'):
                 st.markdown("#### ğŸŒŸ Feature Importance")
                 fi = best_model.feature_importances_
                 fi_df = pd.DataFrame({'Feature': X_tmp.columns, 'Importance': fi}).sort_values(by='Importance', ascending=False).head(10)
                 fig_fi = px.bar(fi_df, x='Importance', y='Feature', orientation='h', title=f"Top 10 Features ({best_model_name})")
                 fig_fi.update_layout(yaxis={'categoryorder':'total ascending'})
                 st.plotly_chart(fig_fi, use_container_width=True)
             
        except Exception as e:
            st.error(f"AutoML Failed: {e}")

    # --- Tensor Gen ---
    st.markdown("---")
    st.subheader("3. ğŸ§  PyTorch Tensor ìƒì„±")
    # Tensor ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
    if st.button("Generate PyTorch Tensors"):
        # 1. Target ë¶„ë¦¬ attempt
        if target_col in final_df.columns:
            # íƒ€ê²Ÿì´ ë³€í˜•ë˜ì§€ ì•Šì•˜ê±°ë‚˜ LabelEncodingëœ ìƒíƒœ
            y = final_df[target_col]
            X = final_df.drop(columns=[target_col])
        else:
            # íƒ€ê²Ÿ ì»¬ëŸ¼ì´ OneHot ë“±ìœ¼ë¡œ ì´ë¦„ì´ ë°”ë€Œì—ˆê±°ë‚˜ ì‚¬ë¼ì¡Œì„ ìˆ˜ ìˆìŒ
            st.warning(f"íƒ€ê²Ÿ ì»¬ëŸ¼ '{target_col}'ì´(ê°€) ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. One-Hot Encoding ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ì´ë¦„ì— target_colì´ í¬í•¨ëœ ì»¬ëŸ¼ë“¤ì„ yë¡œ ê°„ì£¼ (ê°„ì´ ë¡œì§)
            target_cols = [c for c in final_df.columns if str(c).startswith(f"{target_col}_")]
            if target_cols:
                y = final_df[target_cols]
                X = final_df.drop(columns=target_cols)
                st.info(f"íƒ€ê²Ÿìœ¼ë¡œ ì¶”ì •ë˜ëŠ” ì»¬ëŸ¼ë“¤: {target_cols}")
            else:
                st.error("íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ë¥¼ Xë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                X = final_df
                y = pd.Series(np.zeros(len(X))) # Dummy y

        # 2. ë°ì´í„° íƒ€ì… ì •ë¦¬ (Data Type Cleaning)
        try:
            # X ì²˜ë¦¬: bool -> int, object -> numeric (coerce)
            # 1) Bool íƒ€ì… ì²˜ë¦¬
            bool_cols = X.select_dtypes(include=['bool']).columns
            if len(bool_cols) > 0:
                X[bool_cols] = X[bool_cols].astype(int)
            
            # 2) Object íƒ€ì… ê°•ì œ ë³€í™˜
            X = X.apply(pd.to_numeric, errors='coerce').fillna(0)
            
            # 3) ì—¬ì „íˆ ìˆ«ìê°€ ì•„ë‹Œ ì»¬ëŸ¼ ì œê±° (ì•ˆì „ì¥ì¹˜)
            non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns
            if len(non_numeric_cols) > 0:
                st.warning(f"âš ï¸ í…ì„œ ë³€í™˜ ë¶ˆê°€ ì»¬ëŸ¼ ì œê±°ë¨ (Text/Object): {list(non_numeric_cols)}")
                X = X.drop(columns=non_numeric_cols)

            # y ì²˜ë¦¬
            if isinstance(y, pd.DataFrame):
                bool_cols_y = y.select_dtypes(include=['bool']).columns
                if len(bool_cols_y) > 0:
                    y[bool_cols_y] = y[bool_cols_y].astype(int)
                y = y.apply(pd.to_numeric, errors='coerce').fillna(0).values
            else:
                y = pd.to_numeric(y, errors='coerce').fillna(0).values
            
            # ìµœì¢… Numpy ë³€í™˜ (float32)
            X_values = X.values.astype(np.float32)
            y_values = y.astype(np.float32)

            X_train, X_test, y_train, y_test = train_test_split(X_values, y_values, test_size=0.2, random_state=42)
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
            X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)
            y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
            y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)
            
            st.write(f"Device: {device}")
            st.code(f"X_train: {X_train_t.shape}\ny_train: {y_train_t.shape}")
            
            # Save
            buffer = io.BytesIO()
            torch.save({
                'X_train': X_train_t, 'X_test': X_test_t,
                'y_train': y_train_t, 'y_test': y_test_t,
                'feature_names': list(X.columns)
            }, buffer)
            
            st.download_button("ğŸ’¾ Download .pt file", buffer.getvalue(), "data.pt")
            
        except Exception as e:
            st.error(f"í…ì„œ ë³€í™˜ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.write("íŒíŠ¸: ë°ì´í„°ì— í…ìŠ¤íŠ¸ê°€ ë‚¨ì•„ìˆê±°ë‚˜, ë©”ëª¨ë¦¬ ë¶€ì¡±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")